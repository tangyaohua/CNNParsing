"""Pythonic interface to Eugene Charniak's parser.  There are a couple
too many ways to do the following:

    train the parser (train())
    run the parser in parsing or LM mode (get_parser_command(), 
                                          parse_section_of_a_file())
    parse parser results (see Parsing.Trees) as well (get_lm_scores())
    
The language modelling stuff is unfortunately very old and likely does
not work very well.  This file is a level 3 cruft hazard.  This file
still does evaluation via evalb and sparseval (badly) but the newer
evaluation system in Parsing.Evaluation should be used instead."""
from __future__ import nested_scopes
from tempfile import NamedTemporaryFile, mkstemp
from popen2 import Popen3 # one of the worst named python modules
import os, time, re, sys

from Parsing.Trees import NBestTree, NBestTreeReader, UnbalancedParentheses, \
                          TreeReader, TreeConverter
from waterworks.Files import open_file_or_filename, keepable_tempfile
from waterworks.Tools import Symbol
from ExitCodes import ExitCode
from Parsing.evalb import get_fscore_from_evalb, get_evalb_summary

# regex to (roughly) match one float or +/-inf
float_or_inf = r'((?:[\-+]?inf)|(?:[0-9\-\.]+))'
# regex to match 3 float_or_infs, separated by spaces
score_re = re.compile(r'\s+'.join([float_or_inf] * 3) + '\s*$')

CURRENT_PARSER_BASE = '/u/dmcc/rev/reranking-parser/first-stage'
CURRENT_PARSER = os.path.join(CURRENT_PARSER_BASE, 'PARSE', 'parseIt')
CURRENT_TESTER = os.path.join(CURRENT_PARSER_BASE, 'PARSE', 'wwBCTest')
CURRENT_TRAIN_BIN = os.path.join(CURRENT_PARSER_BASE, 'TRAIN')

# TODO maybe provide more default language models (WSJ, Switchboard, etc.)
DEFAULT_LM = '/u/dmcc/rev/reranking-parser/first-stage/DATA/LM/'
DEFAULT_DATA = '/u/dmcc/rev/reranking-parser/first-stage/DATA/EN/'

class ParserError(Exception):
    """Indicates that the parser terminated prematurely and did not parse
    all of the input."""
class BadParserExitCode(ExitCode, ParserError):
    pass
class ParserPrintedErrorMessages(ParserError):
    pass
class MissingScores(ParserError):
    """This is raised when the output of the parser does not have the
    same number of items as the input."""
class TrainingError(Exception):
    """Indicates that there was a problem during training."""

# Indicates that a specific sentence failed in a parse.
ParseFailed = Symbol('ParseFailed')

def get_lm_scores(linelist):
    """Returns an iterator that yields score tuples from a file.
    The file should be one generated by Eugene's parseIt.
    
    linelist can be a list of strings, file object, or anything else
    that yields strings when iterated."""
    for line in linelist:
        match = score_re.match(line)
        if match:
            lm, trigram, mixed = [float(num) for num in match.groups()]
            if mixed == float('-inf'):
                print "ECParser: mixed score was -inf, using max(lm, trigram) instead."
                mixed = max(lm, trigram)
            yield lm, trigram, mixed
        elif line.startswith("Parse failed"):
            yield ParseFailed

def get_parser_command(filename, parser=CURRENT_PARSER, 
    datadir=DEFAULT_LM, maxlength=399, overparse=None, timeit=False,
    mode='lm', case_insensitive=False, silence_failures=False,
    parser_debug_level=None, nbest=None, pretty_print=False, 
    already_tokenized=False, parser_threads=None, 
    reranker=None, reranker_lowercase_words=True,
    reranker_mode='1best', reranker_absolute_counts=False,
    reranker_features=None, reranker_weights=None,
    reranker_debug=None, extra_options='', reranker_extra_options=''):
    """Return the command to run the parser on a specific SGML file.
    reranker_* options go to the reranker.  Set extra_options to use
    any options not currently supported for the first stage parser and
    reranker_extra_options for any options not supported by the second
    stage reranker."""
    datadir = validate_and_cleanup_datadir_path(datadir)

    pieces = [parser]

    # first stage parser options
    assert mode in ('lm', 'parser'), "Parser mode must be 'lm' or 'parser'"
    if mode == 'lm': # TODO suppport other languages
        pieces.append('-L')
        if datadir is None:
            datadir = DEFAULT_LM
    else: # parser
        if datadir is None:
            datadir = DEFAULT_DATA

    # options with values
    for value, flag in ((overparse, 'T'),
                        (maxlength, 'l'),
                        (parser_debug_level, 'd'),
                        (nbest, 'N'),
                        (parser_threads, 't')):
        if value is not None:
            pieces.append('-%s%s' % (flag, value))

    # flags
    for value, flag in ((case_insensitive, 'C'),
                        (timeit, 't'),
                        (silence_failures, 'S'),
                        (already_tokenized, 'K'),
                        (pretty_print, 'P')):
        if value:
            pieces.append('-%s' % flag)

    if extra_options:
        pieces.append(extra_options)

    pieces.extend((datadir, filename))

    reranker_modes = ['1best', 'nbest', 'featcounts']
    # second stage reranker options
    if reranker or reranker_features or reranker_weights or \
        reranker_debug or reranker_extra_options:
        # sanity checks
        assert reranker and reranker_features and reranker_weights, "When using the reranker, you must set all of the reranker, reranker_features, and reranker_weights options"
        assert reranker_mode in reranker_modes, "Reranker mode must be '1best', 'nbest', or 'featcounts'."
        assert nbest is not None and nbest > 1, "First-stage parser must be n-best.  Set the nbest variable."

        # setup pipe to reranker
        pieces.extend(('|', reranker, 
                      '-m %s' % reranker_modes.index(reranker_mode)))
        # flags
        for value, flag in ((reranker_absolute_counts, 'a'),
                            (reranker_lowercase_words, 'l'),
                            (reranker_debug, 'd')):
            if value:
                pieces.append('-%s' % flag)

        if reranker_extra_options:
            pieces.append(reranker_extra_options)

        pieces.extend((reranker_features, reranker_weights))

    command = ' '.join(pieces)
    return command

class ECParser:
    """Methods relevant to running Eugene Charniak's parser."""
    def __init__(self):
        self.pid = None
        self.last_output = None
        self.last_status = None
    def kill_parser(self):
        """Kill the parser if it is running."""
        # TODO: save what we have so far
        if self.pid and self.parser.poll() == -1:
            print "ECParser: Emergency shutdown"

            print "ECParser: Killing parser (PID %s) with SIGTERM" % self.pid
            # ask the parser nicely to shutdown
            os.kill(self.pid, 15)

            # grab whatever we can
            self.last_output = self.parser.fromchild.read()

            if self.last_output:
                print "Parser output -----"
                print self.last_output
                print "End parser output -----"

            pollresult = self.parser.poll()
            if pollresult == -1: # parser hasn't finished
                # so we'll wait a little and then gun it
                time.sleep(0.8)
                if self.parser.poll() == -1: # still not finished
                    print "ECParser: Killing parser with SIGKILL"
                    os.kill(self.pid, 9)

                self.last_status = self.parser.poll()
            else:
                self.last_status = pollresult

            self.pid = None

    def make_sgml_file(self, sentences, filename=None):
        """Returns a file marking up the sentences with <s> tags.
        The input, sentences, is a list of strings.  You may specify
        a filename to produce a file of a specific name, otherwise it
        will return a NamedTemporaryFile which will be deleted when it
        falls out of scope."""
        if not filename:
            f = NamedTemporaryFile()
        else:
            f = file(filename, 'w')
        f.write('\n'.join(["<s> %s </s>" % utterance 
            for utterance in sentences]))
        f.flush()

        return f

    # XXX better docs needed!  also, update docs on sgml_fileobj_or_name
    def parse_sgml_file(self, sgml_fileobj_or_name, output=None,
        debug=False, skip_blank_lines=False, logstream=sys.stdout, 
        error_messages_are_failures=True, **parse_args):
        # TODO these docs are dangerously outdated
        """sgml_fileobj_or_name is an <s> file object, must have
        a filename (i.e. tempfile.TemporaryFile is not okay but a
        tempfile.NamedTemporaryFile is fine).  We run Eugene's parser
        on the sgml_fileobj_or_name and return the output of his parser
        as a string.  See get_parser_command() for a description of
        parse_args."""

        # TODO don't we already have something like this?
        if isinstance(sgml_fileobj_or_name, basestring):
            name = sgml_fileobj_or_name
        else:
            name = sgml_fileobj_or_name.name

        cmd = get_parser_command(name, **parse_args)
        if debug:
            print >>logstream, "ECParser: Running %r" % cmd
            if output:
                print >>logstream, "ECParser: Redirecting output to %r" % output
        logstream.flush()

        # fork and run the parser as a child.  Popen3 objects will give us
        # their stdin/stdout/stderr file handles and PID.
        self.parser = Popen3(cmd, capturestderr=True)
        self.pid = self.parser.pid
        if output: # redirect output
            output_file = open_file_or_filename(output, 'w')
            data = self.parser.fromchild.read()
            if skip_blank_lines:
                lines = data.splitlines()
                for line in lines:
                    if line.strip():
                        output_file.write(data)
            else:
                output_file.write(data)
            output_file.flush()
            self.last_output = "(redirected to %r)" % output

            """
            # this code doesn't handle nbest or LM yet, so I'm taking it out
            # until it is more complete
            # make sure we saw enough output lines or raise MissingScores
            if length_hint is not None and parse_args.get('nbest') == None:
                output_file = file(output, 'r')
                num_output_lines = 0
                for line in output_file:
                    num_output_lines += 1
                num_input_lines = length_hint
                # 2x since there is a blank line between
                if num_output_lines != 2 * num_input_lines:
                    m = "Expected %d lines of output in %s, only found %d"
                    v = (2 * num_input_lines, output, num_output_lines)
                    raise MissingScores(m % v)
            """
        else:
            self.last_output = self.parser.fromchild.read()

        self.last_error = self.parser.childerr.read().strip()
        if self.last_error.strip():
            print >>logstream, "Parser stderr -----"
            print >>logstream, self.last_error
            print >>logstream, "End parser stderr -----"
            logstream.flush()
            if error_messages_are_failures:
                raise ParserPrintedErrorMessages(self.last_error)

        self.last_status = self.parser.wait()
        self.pid = None

        if self.last_status != 0 or debug:
            print >>logstream, "Parser stdout -----"
            print self.last_output
            print >>logstream, "End parser stdout -----"
            logstream.flush()
            if self.last_status != 0:
                raise BadParserExitCode(self.last_status)

        return self.last_output
    def parse(self, sentences, **parse_args):
        """Return the language model probabilities for sentences,
        according to the parser."""
        s_file = self.make_sgml_file(sentences)
        parser_output = self.parse_sgml_file(s_file, **parse_args)
        tree_lines = parser_output.splitlines()
        return tree_lines
    def get_ec_score(self, sentences, **parse_args):
        parse_args['mode'] = 'lm' # force this
        tree_lines = self.parse(sentences, **parse_args)
        scores = list(get_lm_scores(tree_lines))
        if len(scores) != len(sentences):
            raise MissingScores("Parsed only %s scores from %s sentences." % \
                (len(scores), len(sentences)))
        return scores

# TODO: we should be able to return scores+trees as well and handle nbest
def parse(sentences, **parse_args):
    """A helper function for those who just want to parse.  Given a list of
    sentences, returns the scores of each sentence."""
    p = ECParser()
    return p.parse(sentences, **parse_args)

def parse_section_of_a_file(inobj, outobj, datadir, start=None, end=None,
    convert_from_trees=False, keep_temporary_section=False, **parse_args):
    """Generic function to parse just a portion of a file and put the
    outobj into a file.  This function is the workhorse of ParseHog.parse.
    inobj and outobj are either file-like objects or filenames.
    start and end can be None to mean the beginning or end of the file,
    respectively."""
    # note that None is less than all integers and that the empty string
    # is greater than all integers.  thus, if we change end to "" if it is 
    # None, we can compare it with integers properly.
    if end is None:
        end = ""

    input_file = open_file_or_filename(inobj)
    if convert_from_trees:
        input_file = TreeConverter(input_file)
        parse_args['already_tokenized'] = True # set -K

    sliced_file = keepable_tempfile(keep=keep_temporary_section)

    current_line_number = 0
    for line in input_file:
        if start <= current_line_number <= end:
            sliced_file.write(line)
        elif current_line_number > end:
            break
        current_line_number += 1
    sliced_file.flush()
    if (start is None) or (end is ""):
        num_input_lines = None
    else:
        num_input_lines = (start - end) + 1

    parser = ECParser()
    parser.parse_sgml_file(sliced_file, output=outobj, 
        datadir=datadir, **parse_args)

def validate_and_cleanup_datadir_path(datadir):
    """Ensure that our data directory is okay and clean it up to ensure that
    the parser will grok it."""
    if not os.path.exists(datadir):
        raise OSError("Data directory (%s) does not exist." % datadir)
    if not datadir.endswith('/'):
        # the parser will freak out if this doesn't end with a '/'
        datadir += '/'
    return datadir

def train(train_data, dev_data, output_dir, mode='parser',
    train_bin_dir=CURRENT_TRAIN_BIN, original_data=None, verbose=True,
    cat_alternative=None, keep_tempfiles=False):
    """Create a language model / parsing model in output_dir from
    train_data and dev_data.  train_bin_dir is the directory
    containing allScript and the training binaries.  We use original_data
    as our prototype for the model directory, and while most of its
    contents are unimportant, some files like terms.txt are relevant.
    
    To use cat_alternative, you'll need dmcc's version of allScript.
    This lets you specify zcat, bzcat, smartcat, etc. for reading in
    files."""
    if isinstance(train_data, basestring):
        train_data = [train_data]
    if isinstance(dev_data, basestring):
        dev_data = [dev_data]

    assert mode in ('parser', 'lm')
        
    for train_or_dev_filename in train_data + dev_data:
        assert os.path.exists(train_or_dev_filename), \
            "File %s doesn't exist." % train_or_dev_filename

    allScript = os.path.join(train_bin_dir, 'allScript')
    assert os.path.exists(allScript)
    if original_data is None:
        if mode == 'parser':
            original_data = DEFAULT_DATA
        else:
            original_data = DEFAULT_LM
    # output_dir = validate_and_cleanup_datadir_path(output_dir)

    import shutil, commands
    from iterextras import any
    from waterworks.Files import possibly_compressed_file
    # erase the output directory if it exists and remake it from our
    # original_data directory (which should be a clean training of WSJ or
    # switchboard -- it must have the right terms.txt, etc.)
    if output_dir != original_data:
        print "Removing", output_dir
        shutil.rmtree(output_dir, ignore_errors=True)
        print "Copying", original_data, "to", output_dir
        shutil.copytree(original_data, output_dir)

    def compressed_filename(filename):
        filename = filename.lower()
        return filename.endswith('.gz') or filename.endswith('.bz2')

    temp_files = []
    modelbase = "%s." % os.path.basename(output_dir)
    # if there are any compressed files in training, we combined all
    # training into one uncompressed file
    if any(train_data, compressed_filename):
        temp_train = keepable_tempfile(mode='w', prefix=modelbase,
                                       suffix='.train', keep=True, dir='/ltmp')
        print "Uncompressing and combining training data to", temp_train.name
        for filename in train_data:
            f = possibly_compressed_file(filename)
            for line in f:
                temp_train.write(line)
        temp_train.close()
        train_data = [temp_train.name]
        temp_files.append(temp_train)

    # same for dev files
    if any(dev_data, compressed_filename):
        temp_dev = keepable_tempfile(mode='w', prefix=modelbase,
                                     suffix='.dev', keep=True, dir='/ltmp')
        print "Uncompressing and combining dev data to", temp_dev.name
        for filename in dev_data:
            f = possibly_compressed_file(filename)
            for line in f:
                temp_dev.write(line)
        temp_dev.close()
        dev_data = [temp_dev.name]
        temp_files.append(temp_dev)

    # the repr()s will put quotes around lists of arguments
    cmd = ' '.join([allScript, 
                    '-' + mode, 
                    output_dir, 
                    repr(' '.join(train_data)), 
                    repr(' '.join(dev_data))])

    if verbose:
        print "Training command:", repr(cmd)
    
    status, output = commands.getstatusoutput(cmd)

    if verbose:
        print "Output:"
        print "-------"
        print output
        print "-------"

    # store training output
    f = file(os.path.join(output_dir, 'traininglog'), 'a')
    f.write(output)
    f.close()

    if not keep_tempfiles:
        print "Removing temporary training files..."
        for fileobj in temp_files:
            os.remove(fileobj.name)

    if status != 0:
        raise TrainingError("Training script exited with nonzero exit code.")

    warning_messages = ('Exit code: 134', 'Exit code: 137', 'segfault', 'abort',
                        'Could not find', "Assertion `pstStream' failed.")
    for message in warning_messages:
        if message.lower() in output.lower():
            raise TrainingError("Found a warning message in training " + \
                                "output: %r" % message)

    print "Done"
    return output

from twisted.internet import protocol, selectreactor
class AsyncProcess(protocol.ProcessProtocol):
    """Similar to commands.getstatusoutput, but will print the output
    as it appears."""
    def __init__(self):
        self._process_output = ''
        self._event_loop = None
    def run(self, args):
        """Run a program in a subshell.  Returns the output of the command
        and the exit status (in some stupid Twisted Failure object)

        args is a list of arguments (strings).  The first item in args
        should be an executable."""
        self._event_loop = selectreactor.SelectReactor()
        self._event_loop.spawnProcess(self, args[0], args)
        self._event_loop.run()

        # when we get here, the process has stopped since we killed the reactor
        # in processEnded()

        # TODO: make sure status is good
        return (self._process_output, self._status)

    # callbacks from running the process
    def processEnded(self, status):
        self._status = status
        self._event_loop.stop()
    def outReceived(self, data):
        sys.stdout.write(data)
        self._process_output += data
    errReceived = outReceived

# Evaluator is deprecated, see the newer Evaluation class
sparseval_fmeasure_re = re.compile(r'Labeled Bracketing F-measure:\s+(\d+\.\d+)')
class Evaluator(protocol.ProcessProtocol):
    def __init__(self):
        self._process_output = ''
        self._event_loop = None
    def evaluate(self, model_dir, test_data, language_model=False, nbest=None, 
                 per_sentence=False, tester=CURRENT_TESTER, 
                 tester_style='wwbctest'):
        """TBD

        tester is wwBCTest or a drop-in replacement.  tester_style should
        be the output format of the tester, i.e. either 'wwbctest' or
        'evalb'."""
        assert tester_style in ('wwbctest', 'evalb', 'sparseval')
        if tester_style == 'evalb':
            # options that don't make sense to evalb
            assert not (language_model or nbest)
        if per_sentence:
            assert tester_style == 'wwbctest'

        self._event_loop = selectreactor.SelectReactor()

        model_dir = validate_and_cleanup_datadir_path(model_dir)
        testername = tester.split()
        args = testername + [model_dir, test_data]

        # after tester
        if language_model:
            args.insert(1, '-M') 
        if nbest:
            args.insert(1, '-N%d' % nbest)
        if per_sentence:
            args.insert(1, '-i')

        print "Evaluation command:", ' '.join(args)
        self._event_loop.spawnProcess(self, testername[0], args)
        self._event_loop.run()

        # when we get here, the process has stopped since we killed the reactor
        # in processEnded()
        self.check_for_errors()

        if tester_style == 'evalb':
            return self.parse_scores_evalb(language_model, nbest)
        elif tester_style == 'wwbctest':
            return self.parse_scores_wwbctest(language_model, nbest, 
                                              per_sentence)
        else: # sparseval
            return self.parse_scores_sparseval()
    def parse_scores_evalb(self, language_model, nbest):
        # we only do 1-best parsing scores (no language modelling or 
        # oracle scores)
        all_sents, short_sents = get_fscore_from_evalb(self._process_output)
        return all_sents / 100.0
    def parse_scores_sparseval(self):
        (all_sents,) = sparseval_fmeasure_re.findall(self._process_output)
        return float(all_sents) / 100.0
    def parse_scores_wwbctest(self, language_model, nbest, per_sentence):
        # TODO: per_sentence is ignored
        last_line = self._process_output.splitlines()[-1]
        if language_model:
            try:
                return get_lm_scores([last_line]).next()
            except StopIteration: # there was an error and we didn't get a score
                raise ValueError("Unparsable results from tester")
        else:
            if nbest:
                oracle_numbers = [float(i) for i in last_line.split()]
                # starting from 1, every 2
                return oracle_numbers[1::2]
            else:
                num, fscore = last_line.split()
                return float(fscore)
    def check_for_errors(self):
        output = self._process_output.lower()
        warning_messages = ('Exit code: 134', 'segfault', 'abort',
                            'Could not find', "Assertion `pstStream' failed.")
        for message in warning_messages:
            if message.lower() in output:
                raise ParserError("Found a warning message in " + \
                                  "output: %r" % message)

    # callbacks from running the process
    def processEnded(self, status):
        self._event_loop.stop()
        from twisted.internet.error import ProcessTerminated
        if isinstance(status.value, ProcessTerminated):
            # we'll convert it into our own (better) exception type
            exitcode = status.value.status # so I hear... but not from 
                                           # Twisted docs >:(
            raise BadParserExitCode(exitcode)
    def outReceived(self, data):
        # this behavior here is a StreamTee
        sys.stdout.write(data)
        self._process_output += data
        sys.stdout.flush()
    errReceived = outReceived

if __name__ == "__main__":
    print parse(["this is a sentence",
                 "this is also a sentence",
                 "this is a fairly long sentence and this is the second half of that fairly long sentence and this would be the third half but there are only two halves."], mode='parser', datadir=DEFAULT_DATA, debug=True)
